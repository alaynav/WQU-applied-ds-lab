# WQU Applied Data Science Lab
Below is an overview of all eight projects that I completed during my enrollment at WorldQuant University (WQU), each designed to enhance my understanding of key data science concepts through data exploration, cleaning, analysis, and modeling. Using real-world datasets, I devoted one month per project and over 200 hours to Python/Jupyter Notebook.

1) **Housing in Mexico**: Learners use a dataset of 21,000 properties to determine if real estate prices are influenced more by property size or location. They import and clean data from a CSV file, build data visualizations, and examine the relationship between two variables using correlation.
    * Explored the impact of property size versus location on real estate prices
    * Utilized pandas DataFrame for data loading and cleaning
    * Created insightful visualizations to examine the relationship between variables

2) **Apartment Sales in Buenos Aires**: Learners build a linear regression model to predict apartment prices in Argentina. They create a data pipeline to impute missing values and encode categorical features, and they improve model performance by reducing overfitting.
    * Built a linear regression model to predict apartment prices in Argentina
    * Implemented a machine learning pipeline with feature encoding and imputation
    * Visualized model coefficients and insights using Mapbox scatter plots and heatmaps

3) **Air Quality in Nairobi**: Learners build an ARMA time-series model to predict particulate matter levels in Kenya. They extract data from a MongoDB database using pymongo, and improve model performance through hyperparameter tuning.
    * Developed an ARMA time-series model to predict particulate matter levels in Kenya
    * Retrieved data from a MongoDB database and performed time series data exploration
    * Tuned hyperparameters for improved model performance

4) **Earthquake Damage in Nepal**: Learners build logistic regression and decision tree models to predict earthquake damage to buildings. They extract data from a SQLite database, and reveal the biases in data that can lead to discrimination.
    * Constructed logistic regression and decision tree models to predict earthquake damage to buildings
    * Extracted data from a SQL database and performed model evaluation through train-test splits
    * Fine-tuned model hyperparameters for enhanced predictive accuracy

5) **Bankruptcy in Poland**: Learners build random forest and gradient boosting models to predict whether a company will go bankrupt. They navigate the Linux command line, address imbalanced data through resampling, and consider the impact of performance metrics precision and recall.
    * Built random forest and gradient boosting models to predict company bankruptcy
    * Handled imbalanced data using resampling techniques
    * Evaluated model performance using precision and recall metrics

6) **Customer Segmentation in the U.S.**: Learners build a k-means model to cluster US consumers into groups. They use principal component analysis (PCA) for data visualization, and they create an interactive dashboard with Plotly Dash.
    * Employed k-means clustering to segment U.S. consumers into distinct groups
    * Conducted exploratory data analysis and feature selection for clustering
    * Deployed a Dash web application for interactive visualization

7) **A/B Testing at WorldQuant University**: Learners conduct a chi-square test to determine if sending an email can increase program enrollment at WQU. They build custom Python classes to implement an ETL process, and they create an interactive data application following a three-tiered design pattern.
    * Conducted chi-square tests to assess the impact of email campaigns on program enrollment
    * Designed experiments and analyze results using statistical methods
    * Built an interactive web application for data visualization and analysis

8) **Volatility Forecasting in India**: Learners create a GARCH time series model to predict asset volatility. They acquire stock data through an API, clean and store it in a SQLite database, and build their own API to serve model predictions.
    * Created a GARCH time series model to predict asset volatility
    * Retrieve data from web APIs and load it into a SQL database.
    * Build a custom web API to serve model predictions

Thank you to WorldQuant for providing such an incredible resource and learning experience!   

***

**Note**: The code content of each project cannot be uploaded due to copyright issues.   
**Verify**: https://www.credly.com/badges/6182d8c4-d30d-4fce-873b-ed3daca942fa/public_url
